{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from gru_model import Model\n",
    "\n",
    "def load_dataset(path):\n",
    "    d = pickle.load( open( path, \"rb\" ) )\n",
    "    return d['x_test'], d['vocab']\n",
    "\n",
    "def batches(data, batch_size):\n",
    "    \"\"\" Yields batches of sentences from 'data', ordered on length. \"\"\"\n",
    "    random.shuffle(data)\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        sentences = data[i:i + batch_size]\n",
    "        sentences.sort(key=lambda l: len(l), reverse=True)\n",
    "        yield [torch.LongTensor(s) for s in sentences]\n",
    "\n",
    "def step(model, sents, device, n):\n",
    "    \"\"\" Performs a model inference for the given model and sentence batch.\n",
    "    Returns the model otput, total loss and target outputs. \"\"\"\n",
    "    if n == 0:\n",
    "        x = nn.utils.rnn.pack_sequence([s[0].unsqueeze(0) for s in sents])\n",
    "        y = nn.utils.rnn.pack_sequence([s[0].unsqueeze(0) for s in sents])\n",
    "    else:\n",
    "        print([s[n] for s in sents])\n",
    "        x = nn.utils.rnn.pack_sequence([s[:n] for s in sents])\n",
    "        y = nn.utils.rnn.pack_sequence([s[n].unsqueeze(0) for s in sents])\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "    out = model(x)\n",
    "    return out, y\n",
    "\n",
    "def calc_accuracy(output_distribution, targets , n):\n",
    "    \n",
    "    # extract item index of largest item prob\n",
    "    prediction = torch.argmax(output_distribution, dim=1)\n",
    "    \n",
    "    # extract every n element\n",
    "    if n > 1:\n",
    "        prediction = prediction[n-1::n] \n",
    "    \n",
    "    num_correct_prediction = (prediction == targets).float().sum()\n",
    "    return num_correct_prediction.item()/targets.shape[0]\n",
    "\n",
    "def topk_accuracy(output_distribution, targets, k, n):\n",
    "    _, pred = torch.topk(input=output_distribution, k=k, dim=1)\n",
    "    if n > 1:\n",
    "        pred = pred[n-1::n] \n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.expand_as(pred))\n",
    "    return correct.sum().item() / targets.shape[0]\n",
    "\n",
    "def test_accuracy(state_dict,data):\n",
    "    device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "    x_test, vocab = load_dataset(data)\n",
    "    model = Model(vocab_size=214, embedding_dim=20, hidden_dim=100, gru_layers=1, dropout=0.0)\n",
    "    batch_size = 200\n",
    "    model.load_state_dict(torch.load(state_dict))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    n = 3\n",
    "    test_accuracies = []\n",
    "    top2_accuracies = []\n",
    "    top3_accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for sents in batches(x_test, batch_size):\n",
    "            out, y = step(model, sents, device, n)\n",
    "            test_accuracies.append(calc_accuracy(out,y.data, n))\n",
    "            top2_accuracies.append(topk_accuracy(out,y.data, 2, n))\n",
    "            top3_accuracies.append(topk_accuracy(out,y.data, 3, n))\n",
    "    return np.mean(test_accuracies), np.mean(top2_accuracies), np.mean(top3_accuracies)\n",
    "\n",
    "def roundoff(num):\n",
    "    return \"{:.5f}\".format(num)\n",
    "\n",
    "def test_run():\n",
    "    state_dicts = [\n",
    "        'state_dicts/state_dict_short_lstm.pth'\n",
    "    ]\n",
    "    data = [\n",
    "        './data/short_sessions.p'\n",
    "    ]\n",
    "    p1, p2, p3 = [], [], []\n",
    "    for i in range(3):\n",
    "        a, b, c = test_accuracy(state_dicts[0],data[0])\n",
    "        p1.append(a)\n",
    "        p2.append(b)\n",
    "        p3.append(c)\n",
    "    \n",
    "    print(roundoff(np.mean(p1)),'$\\pm$', roundoff(np.std(p1)), '&', roundoff(np.mean(p2)),'$\\pm$', roundoff(np.std(p2)), '&', roundoff(np.mean(p3)),'$\\pm$', roundoff(np.std(p3)), '\\\\\\\\') \n",
    "    \n",
    "    print('test accuracy',np.mean(p1),np.std(p1))\n",
    "    print('test top 2 accuracy',np.mean(p2),np.std(p2))\n",
    "    print('test top 3 accuracy',np.mean(p3),np.std(p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b68f4e87af31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/short_sessions.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'state_dicts/state_dict_short_lstm.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-6e04506b7741>\u001b[0m in \u001b[0;36mtest_accuracy\u001b[0;34m(state_dict, data)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m214\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6e04506b7741>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_accuracy('./data/short_sessions.p','state_dicts/state_dict_short_lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
